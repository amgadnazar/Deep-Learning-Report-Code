rnn_basic_imdb.py:
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, SimpleRNN

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)

X_train = pad_sequences(X_train, maxlen=200)
X_test = pad_sequences(X_test, maxlen=200)

model_rnn = Sequential([
    Embedding(input_dim=10000, output_dim=128, input_length=200),
    SimpleRNN(64),
    Dense(1, activation='sigmoid')
])

model_rnn.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model_rnn.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)

loss, accuracy = model_rnn.evaluate(X_test, y_test)
print("Test Accuracy:", accuracy)


rnn_with_metrics_and_plots.py:
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, Dropout
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
=
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)

X_train = pad_sequences(X_train, maxlen=200)
X_test = pad_sequences(X_test, maxlen=200)


model_rnn = Sequential([
    Embedding(input_dim=10000, output_dim=128, input_length=200),
    SimpleRNN(64, return_sequences=False),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model_rnn.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)


history = model_rnn.fit(
    X_train,
    y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)


loss, accuracy = model_rnn.evaluate(X_test, y_test, verbose=0)
print("\nTest Accuracy:", accuracy)


y_pred_prob = model_rnn.predict(X_test)
y_pred_classes = (y_pred_prob > 0.5).astype(int).flatten()

print("\nClassification Report:")
print(classification_report(y_test, y_pred_classes))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_classes))



plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('RNN Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.show()

plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('RNN Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.show()

rnn_with_training_time_analysis.py:
import numpy as np
import time   
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, Dropout
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt


(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)

X_train = pad_sequences(X_train, maxlen=200)
X_test = pad_sequences(X_test, maxlen=200)


model_rnn = Sequential([
    Embedding(input_dim=10000, output_dim=128, input_length=200),
    SimpleRNN(64, return_sequences=False),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model_rnn.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)


start_time = time.time()   

history = model_rnn.fit(
    X_train,
    y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)

end_time = time.time()     
training_time = end_time - start_time

print("\nTotal Training Time: {:.4f} seconds".format(training_time))


loss, accuracy = model_rnn.evaluate(X_test, y_test, verbose=0)
print("\nTest Accuracy:", accuracy)


y_pred_prob = model_rnn.predict(X_test)
y_pred_classes = (y_pred_prob > 0.5).astype(int).flatten()

print("\nClassification Report:")
print(classification_report(y_test, y_pred_classes))

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_classes))

plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('RNN Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.show()

plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('RNN Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.show()

rnn_advanced_metrics_roc_mcc.py:

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
    matthews_corrcoef
)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences


vocab_size = 10000
max_length = 200

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)

X_train = pad_sequences(X_train, maxlen=max_length)
X_test = pad_sequences(X_test, maxlen=max_length)


rnn_model = Sequential([
    Embedding(vocab_size, 64, input_length=max_length),
    SimpleRNN(64, activation='tanh'),
    Dense(1, activation='sigmoid')
])

rnn_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)


history = rnn_model.fit(
    X_train, y_train,
    epochs=5,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)


test_loss, test_acc = rnn_model.evaluate(X_test, y_test, verbose=0)
print("Test Accuracy:", test_acc)

y_prob = rnn_model.predict(X_test).ravel()

y_pred = (y_prob >= 0.5).astype(int)

cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

print("Confusion Matrix:")
print(cm)


specificity = tn / (tn + fp)
print("Specificity:", specificity)

mcc = matthews_corrcoef(y_test, y_pred)
print("Matthews Correlation Coefficient (MCC):", mcc)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

print("AUC Score:", roc_auc)

plt.figure()
plt.plot(fpr, tpr)
plt.plot([0,1], [0,1], linestyle='--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - RNN")
plt.show()

rnn_hyperparameter_experiments.py:
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, Dropout
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef
import time


num_words = 10000
maxlen = 200
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)

X_train = pad_sequences(X_train, maxlen=maxlen)
X_test = pad_sequences(X_test, maxlen=maxlen)


configs = [
    {"rnn_units": 32, "dropout": 0.3, "embedding_dim": 64},
    {"rnn_units": 64, "dropout": 0.5, "embedding_dim": 128},
    {"rnn_units": 128, "dropout": 0.3, "embedding_dim": 128},
]


results = []

for cfg in configs:
    print("\nTraining RNN with config:", cfg)
    
    start_time = time.time()
    
    model_rnn = Sequential([
        Embedding(input_dim=num_words, output_dim=cfg["embedding_dim"], input_length=maxlen),
        SimpleRNN(cfg["rnn_units"], return_sequences=False),
        Dropout(cfg["dropout"]),
        Dense(1, activation='sigmoid')
    ])
    
    model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    history = model_rnn.fit(
        X_train,
        y_train,
        epochs=5,
        batch_size=64,
        validation_split=0.2,
        verbose=1
    )
    
    loss, accuracy = model_rnn.evaluate(X_test, y_test, verbose=0)
    
    y_prob = model_rnn.predict(X_test).flatten()
    y_pred = (y_prob > 0.5).astype(int)
    
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    specificity = tn / (tn + fp)
    mcc = matthews_corrcoef(y_test, y_pred)
    auc_score = roc_auc_score(y_test, y_prob)
    train_time = time.time() - start_time
    
    results.append({
        "RNN Units": cfg["rnn_units"],
        "Dropout": cfg["dropout"],
        "Embedding Dim": cfg["embedding_dim"],
        "Accuracy": accuracy,
        "Specificity": specificity,
        "MCC": mcc,
        "AUC": auc_score,
        "Training Time (s)": train_time
    })
    
    print("Confusion Matrix:\n", cm)
    print("Specificity:", specificity)
    print("MCC:", mcc)
    print("AUC:", auc_score)
    print("Test Accuracy:", accuracy)

import pandas as pd
df_results = pd.DataFrame(results)
print("\nAll Configurations Results:\n")
print(df_results)

lstm_imdb_64_units.py:
import tensorflow as tf
from tensorflow import keras
import time

max_features = 10000
maxlen = 200

(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)

X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)

model = keras.Sequential([
    keras.layers.Embedding(max_features, 128),
    keras.layers.LSTM(64),
    keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

start = time.time()
model.fit(X_train, y_train, epochs=3, batch_size=64)
end = time.time()

loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)
print("Training Time:", end - start)

lstm_imdb_32_units.py:
import tensorflow as tf
from tensorflow import keras
import time

max_features = 10000
maxlen = 200

(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)

X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)

model = keras.Sequential([
    keras.layers.Embedding(max_features, 128),
    keras.layers.LSTM(32),
    keras.layers.Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

start = time.time()
model.fit(X_train, y_train, epochs=3, batch_size=64)
end = time.time()

loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)
print("Training Time:", end - start)
